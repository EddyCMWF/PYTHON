{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (15.,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#File and dir\n",
    "IN_DIR='/users/global/albmar/CarboBiocrop/Brattleby/data/'\n",
    "IN_FILE=IN_DIR+'Marta+Brattleby_arable_flux_2012-12.dat'\n",
    "\n",
    "OUTFILE='/prj/GREENHOUSE/GREENHOUSE_sites/data/Brattleby/ConCrop_FullFlux_data_albmar.nc'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Gap filled sensible heat flux', 'Gap filled latent heat flux', 'Fraction measured latent heat present ', 'Gap filled NEE', 'fraction measured NEE present', 'Total ecosystem respiration', 'GPP \\n']\n",
      "['', 'W m-2', 'W m-2', '-', 'mmol CO2 m-2 s-1', '-', 'mmol CO2 m-2 s-1', 'mmol CO2 m-2 s-1\\n']\n"
     ]
    }
   ],
   "source": [
    "INlines=open(IN_FILE,'r').readlines()\n",
    "headers=INlines.pop(0).split('\\t')\n",
    "print(headers)\n",
    "units=INlines.pop(0).split('\\t')\n",
    "print(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wk_hdrs=['Date','SHF','LHF','LHF_frac','NEE','NEE_frac','TER','GPP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0897ce19193c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mDate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mData_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mData_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mDate_Num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'days since 00:00:00 01-01-2012'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhdr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwk_hdrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.date2num (netCDF4/_netCDF4.c:59018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._dateparse (netCDF4/_netCDF4.c:57654)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/users/eow/edwcom/miniconda3/lib/python3.5/site-packages/netcdftime/netcdftime.py\u001b[0m in \u001b[0;36m_parse_date\u001b[0;34m(datestring)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;31m#    groups[\"fraction\"] = int(float(\"0.%s\" % groups[\"fraction\"]) * 1e6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0miyear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miyear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"month\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"day\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hour\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"minute\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"second\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mtzoffset_mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "Data_Dict={ hdr:[] for hdr in wk_hdrs}\n",
    "for line in INlines:\n",
    "    split=line[:-1].split('\\t')\n",
    "    for hdr,val in zip(wk_hdrs,split):\n",
    "        if hdr=='Date':\n",
    "            Data_Dict[hdr].append(val)\n",
    "        else:\n",
    "            Data_Dict[hdr].append(float(val))\n",
    "\n",
    "Data_Dict['Date'] =np.array( [dt.strptime(date,'%d-%b-%Y') for date in Data_Dict['Date'] ] )\n",
    "Date=Data_Dict['Date']\n",
    "del Data_Dict['Date']\n",
    "\n",
    "for hdr in wk_hdrs[1:]:\n",
    "    Data_Dict[hdr]=np.array(Data_Dict[hdr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Date_Num = nc.date2num(Date,units='days since 2012-01-01 00:00:00')\n",
    "Data_Dict['date']=Date_Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame=pd.DataFrame(Data_Dict)#,index=Date_Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ENCODING= { wk_hdrs[ihdr]: {'dtype':'float32','fill_value':-9999.,'units':units[ihdr]} \\\n",
    "                for ihdr in range(1,len(wk_hdrs)) }\n",
    "ENCODING['date']={'dtype':'float32','units':'days since 2012-01-01 00:00:00'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outf=nc.Dataset(OUTFILE,'w')\n",
    "\n",
    "outf.createDimension('date',len(Date_Num))\n",
    "for var in Data_Dict:\n",
    "    outvar=outf.createVariable(var,'float32',('date'),fill_value=-9999)\n",
    "    for att in ENCODING[var]:\n",
    "        outvar.setncattr(att,ENCODING[var][att])\n",
    "    outvar[:]=Data_Dict[var][:]\n",
    "\n",
    "outf.title='Brattelby Flux Tower Data'\n",
    "outf.owner='Edward Comyn-Platt'\n",
    "outf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_Xarr=DataFrame.to_xarray()\n",
    "DF_Xarr.to_netcdf(OUTFILE)#,encoding=ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_netcdf in module xarray.core.dataset:\n",
      "\n",
      "to_netcdf(path=None, mode='w', format=None, group=None, engine=None, encoding=None) method of xarray.core.dataset.Dataset instance\n",
      "    Write dataset contents to a netCDF file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : str, optional\n",
      "        Path to which to save this dataset. If no path is provided, this\n",
      "        function returns the resulting netCDF file as a bytes object; in\n",
      "        this case, we need to use scipy.io.netcdf, which does not support\n",
      "        netCDF version 4 (the default format becomes NETCDF3_64BIT).\n",
      "    mode : {'w', 'a'}, optional\n",
      "        Write ('w') or append ('a') mode. If mode='w', any existing file at\n",
      "        this location will be overwritten.\n",
      "    format : {'NETCDF4', 'NETCDF4_CLASSIC', 'NETCDF3_64BIT', 'NETCDF3_CLASSIC'}, optional\n",
      "        File format for the resulting netCDF file:\n",
      "    \n",
      "        * NETCDF4: Data is stored in an HDF5 file, using netCDF4 API\n",
      "          features.\n",
      "        * NETCDF4_CLASSIC: Data is stored in an HDF5 file, using only\n",
      "          netCDF 3 compatible API features.\n",
      "        * NETCDF3_64BIT: 64-bit offset version of the netCDF 3 file format,\n",
      "          which fully supports 2+ GB files, but is only compatible with\n",
      "          clients linked against netCDF version 3.6.0 or later.\n",
      "        * NETCDF3_CLASSIC: The classic netCDF 3 file format. It does not\n",
      "          handle 2+ GB files very well.\n",
      "    \n",
      "        All formats are supported by the netCDF4-python library.\n",
      "        scipy.io.netcdf only supports the last two formats.\n",
      "    \n",
      "        The default format is NETCDF4 if you are saving a file to disk and\n",
      "        have the netCDF4-python library available. Otherwise, xarray falls\n",
      "        back to using scipy to write netCDF files and defaults to the\n",
      "        NETCDF3_64BIT format (scipy does not support netCDF4).\n",
      "    group : str, optional\n",
      "        Path to the netCDF4 group in the given file to open (only works for\n",
      "        format='NETCDF4'). The group(s) will be created if necessary.\n",
      "    engine : {'netcdf4', 'scipy', 'h5netcdf'}, optional\n",
      "        Engine to use when writing netCDF files. If not provided, the\n",
      "        default engine is chosen based on available dependencies, with a\n",
      "        preference for 'netcdf4' if writing to a file on disk.\n",
      "    encoding : dict, optional\n",
      "        Nested dictionary with variable names as keys and dictionaries of\n",
      "        variable specific encodings as values, e.g.,\n",
      "        ``{'my_variable': {'dtype': 'int16', 'scale_factor': 0.1, 'zlib': True}, ...}``\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DF_Xarr.to_netcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
